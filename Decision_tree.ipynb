{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](https://github.com/thesouth97/Code/blob/master/wether_tree.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather.csv')\n",
    "df = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    \n",
    "    n_rows, m_columns = df.shape\n",
    "    indices = np.arange(0, n_rows).tolist()\n",
    "    test_indices = random.sample(population=indices, k=int(n_rows*test_size))\n",
    "    test_df = df.iloc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(df):\n",
    "    labels = df.iloc[:,-1]\n",
    "    labels_unique = np.unique(labels)\n",
    "    if labels_unique.shape[0] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(df):\n",
    "    \n",
    "    labels = df.iloc[:,-1]\n",
    "    labels_unique, counts = np.unique(labels, return_counts=True)\n",
    "    index_max = np.argmax(counts)\n",
    "    classification = labels_unique[index_max]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_split(df):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    columns = df.columns\n",
    "    n_rows, n_cols = df.shape\n",
    "    for col in range(n_cols - 1):\n",
    "        features = df[columns[col]].tolist()\n",
    "        unique_features = np.unique(features).tolist()\n",
    "\n",
    "        potential_splits[columns[col]] = unique_features\n",
    "        \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, split_column, split_feature):\n",
    "    \n",
    "    data_same_feature = df[df[split_column] == str(split_feature)]\n",
    "    data_different_feature = df[df[split_column] != str(split_feature)]\n",
    "    \n",
    "    return data_same_feature, data_different_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_column(df, split_column):\n",
    "    \n",
    "    df_features = []\n",
    "    features = df[split_column].tolist()\n",
    "    unique_features = np.unique(features)\n",
    "    for i in unique_features:\n",
    "        data_same_feature = df[df[split_column] == i]\n",
    "        df_features.append(data_same_feature)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest overall entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(df):\n",
    "    \n",
    "    labels = df.iloc[:,-1].tolist()\n",
    "    _, num = np.unique(labels, return_counts=True)\n",
    "    probability = num*1.0/np.sum(num)\n",
    "    entropy = np.sum(-probability*np.log(probability))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_same_feature, data_different_feature):\n",
    "    \n",
    "    num1 = data_same_feature.shape[0]\n",
    "    num2 = data_different_feature.shape[0]\n",
    "    \n",
    "    num = num1 + num2\n",
    "    \n",
    "    p1 = calculate_entropy(data_same_feature)\n",
    "    p2 = calculate_entropy(data_different_feature)\n",
    "    \n",
    "    overall_entropy = p1*(num1*1.)/num + p2*(num2*1.)/num\n",
    "    \n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(df, potential_split):\n",
    "    \n",
    "    overall_entropy = 1000\n",
    "    for columns_index in potential_split:\n",
    "        for feature in potential_split[columns_index]:\n",
    "            data_same_feature, data_different_feature = split_data(df, columns_index, feature)\n",
    "            curr_overall_entropy = calculate_overall_entropy(data_same_feature, data_different_feature)\n",
    "            if curr_overall_entropy < overall_entropy:\n",
    "                overall_entropy = curr_overall_entropy\n",
    "                best_column_split = columns_index\n",
    "                best_feature_split = feature\n",
    "    return best_column_split, best_feature_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub_tree = {question: [yes_answer, no_answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_example = {'outlook = sunny':[{'hummidity = normal':['play'], \n",
    "                                    'hummidity = high':['no']}], \n",
    "                \n",
    "                'outlook = overcast':['play'], \n",
    "                \n",
    "                'outlook = rainy':[{'wind = weak':['play'], \n",
    "                                    'wind = strong':['no']}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decition_tree(df, counter=0, max_depth=5):\n",
    "    if counter == 0:\n",
    "        global columns\n",
    "        \n",
    "        columns = df.columns\n",
    "        data = df\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    if (check_purity(data)) or max_depth == counter:\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    else:\n",
    "        counter += 1\n",
    "        potential_split = get_potential_split(data)\n",
    "        best_split_column, best_split_feature = determine_best_split(data, potential_split)\n",
    "        data_same_feature, data_different_feature = split_data(data, best_split_column, best_split_feature)\n",
    "      \n",
    "        question= '{} = {}'.format(best_split_column, best_split_feature)\n",
    "        sub_tree = {question:[]}\n",
    "        \n",
    "        answer1 = Decition_tree(data_same_feature, counter, max_depth)\n",
    "        answer2 = Decition_tree(data_different_feature, counter, max_depth)\n",
    "        sub_tree[question].append(answer1)\n",
    "        sub_tree[question].append(answer2)\n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outlook = sunny': [{'humidity = high': ['no', 'yes']},\n",
      "                     {'wind = strong': ['no', 'yes']}]}\n"
     ]
    }
   ],
   "source": [
    "tree = Decition_tree(train_df, counter=0, max_depth=2)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    columns, compare_opertor, features = question.split()\n",
    "\n",
    "    if example[columns] == features:\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        \n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df, tree):\n",
    "    lst_example = []\n",
    "    true_labels = df.iloc[:,-1].tolist()\n",
    "    pred_labels = []\n",
    "    num_test = df.shape[0]\n",
    "    for i in range(num_test):\n",
    "        lst_example.append(df.iloc[i,:])\n",
    "        \n",
    "    for example in lst_example:\n",
    "        predict = classify_example(example, tree)\n",
    "        pred_labels.append(predict)\n",
    "    \n",
    "    lst = []\n",
    "    for i in range(len(pred_labels)):\n",
    "        if pred_labels[i] == true_labels[i]:\n",
    "            lst.append(True)\n",
    "        else:\n",
    "            lst.append(False)\n",
    "    lst = np.asarray(lst)\n",
    "    acc = lst.mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_df, tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
